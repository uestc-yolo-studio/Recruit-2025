---
title: 机器学习
sidebar: true
author:
  - name: 陈晓阳
    url: ""
  - name: 刘艺晗
    url: "https://icyuil.top"
---
## 提交方式

### 提交地址

@刘艺晗 yuilicarus@gmail.com (提交后请确保收到确认回复)

### 提交要求

请将文件按照题目分成不同文件夹，文件夹命名方式为ML＋本题序号（如第一题文件夹名字应该为`ML01`）。在每个文件夹里，应该有本题的源代码`.py`文件，并且有包含编译运行结果的截图以及思考题答案的pdf文件（为美观，可先写markdown文档，再由markdown转换成pdf文件），文件命名方式同上（如第一题文件夹里应包含`ML01.py`和`ML01.pdf`），最后打包成`.7z`压缩包，重命名为`学号-姓名-ML`（如`2025090901001-灵梦-ML`）

## 引入

![](assets/Evolutionary_Tree.png)

实践是检验真理的唯一标准，自从2022年11月30日ChatGPT发布以来，大语言模型已经遍地开花，站在浪潮之上，得益于开源精神，我们每个人都能掌握其中的原理

### 机器学习是什么

**机器学习**是[人工智能](https://zh.wikipedia.org/wiki/人工智能)的一个分支。人工智能的研究历史有着一条从以“[推理](https://zh.wikipedia.org/wiki/推理)”为重点，到以“[知识](https://zh.wikipedia.org/wiki/知识)”为重点，再到以“[学习](https://zh.wikipedia.org/wiki/学习)”为重点的自然、清晰的脉络。显然，机器学习是实现人工智能的一个途径之一，即以机器学习为手段，解决人工智能中的部分问题。机器学习在近30多年已发展为一门多领域[科际集成](https://zh.wikipedia.org/wiki/科际整合)，涉及[概率论](https://zh.wikipedia.org/wiki/概率论)、[统计学](https://zh.wikipedia.org/wiki/统计学)、[逼近论](https://zh.wikipedia.org/wiki/逼近论)、[凸分析](https://zh.wikipedia.org/wiki/凸分析)、[计算复杂性理论](https://zh.wikipedia.org/wiki/计算复杂性理论)等多门学科。

大语言模型隶属于机器学习中深度学习的部分，是[机器学习](https://zh.wikipedia.org/wiki/机器学习)的分支，是一种以[人工神经网络](https://zh.wikipedia.org/wiki/人工神经网络)为架构，对资料进行表征学习的[算法](https://zh.wikipedia.org/wiki/算法)。深度学习中的形容词“深度”是指在网络中使用多层。

通过学习上述技术，我们能够做到图像分类，目标检测，进一步延伸到当下火热的AI绘画，AI语音，聊天模型等，相信未来AI一定会孵化出更多迷人的应用。

### 为什么选择机器学习

通过机器学习，你能感受到当下最新的AI技术如何改善我们的生活，如果你觉得知识与代码十分枯燥，那么我们十分推荐两个在当下火热的AI应用：

AI文生图：可以通过B站up主[秋葉aaaki](https://space.bilibili.com/12566101)的ComufyUI来入手，

AI文生音：建议通过B站up主[痕继痕迹](https://space.bilibili.com/39337803)的GPT-SoVITS项目尝试AI声音模拟

通过上面两种方式，你能感受到最前沿的AI科技以及两位up主无私的开源精神。经过系统学习，相信你也可以创造自己的AI应用。

### 学习路线推荐

#### 第一步：了解机器学习

机器学习在当下有哪些细分方向？

每个方向有哪些技术应用or成果？

你对机器学习的哪个方向更感兴趣？

以上都是可以尝试以去找到兴趣的目的性问题

#### 第二步：技术上初试机器学习

再次推荐吴恩达老师的课程，对于入门来讲轻松易懂。但是注意，也需要一定的微积分，线代知识，希望你能够提前了解如下数学知识：导数，偏导数，矩阵运算

[【中英字幕】吴恩达机器学习系列课程 ]( https://www.bilibili.com/video/BV164411b7dx/?share_source=copy_web&vd_source=51c4fb30e90a316b418932d56041e4aa)

同时推荐一本通俗易懂的书：《深度学习入门 基于PyTorch的理论与实现》

当你看完视频，相比能够对机器学习有一定程度的了解，那么接下来建议进入实操环节

#### 第三步：环境配置

配置环境是未来大学生活中必不可少的事情，从C语言开始，就必须为自己创设敲代码的环境，推荐使用PyTorch作为你的第一款人工智能框架：[最详细的 Windows 下 PyTorch 入门深度学习环境安装与配置 CPU GPU 版 | 土堆教程]( https://www.bilibili.com/video/BV1S5411X7FY/?share_source=copy_web&vd_source=51c4fb30e90a316b418932d56041e4aa)

Anaconda是一款管理电脑上python环境的工具，能够让你非常便捷地实现python包的安装，环境的隔离等，而PyCharm是一款流行的python IDE

>如果环境配置有问题可以试试[趋动云](https://platform.virtaicloud.com/gemini_web/auth/register?inviteCode=4a5a92df194bb94c675b6888b68c41fe)

#### 第四步：Python

PyTorch框架本身基于python语法格式，python作为解释性语言，性能上较低，但是对于初学者来讲可读性强，代码格式在缩进上也能够一定程度上规范

>可能学习路线并不完善，但是后面的题目也是由易到难的，倘若过程中遇到了不懂而且又不知应该去学习哪方面知识的情况，欢迎向出题人提问

## 题目

### 任务一：梯度下降——灵梦与魔理沙的结界修复

![](assets/Reimu_and_Marisa.png)

最近博丽神社的结界突然出现了异常，灵梦发现结界能量不稳，周围的灵力波动时强时弱。为了防止神社被灵力暴走毁坏，灵梦决定必须找到结界的最小能量点，稳定它的力量。她找来了擅长各种复杂魔法计算的魔理沙帮忙。

- **灵梦:** 魔理沙，我得修复神社的结界，但是能量老是不稳定。你说过用数学方法能找出结界的最佳平衡点，有办法帮我吗？
- **魔理沙:** 哼，看来你终于意识到我的聪明了！没错，我有办法。我们可以用一种叫“梯度下降”的方法来找到结界能量的极小值，这样它就会稳定下来。

魔理沙拿出了她的魔法笔记，展示了一张能量函数的曲线:

**y  =  2x^5 + x^4 - 11x^3 + 7x^2 + 2x**

她告诉灵梦，能量在这个方程中随 **x** 变化。她们的任务就是通过梯度下降来找到这个方程的极小值，稳定神社结界。

**任务**

1. 在区间 **x[-0.5, 1.5] , y[-1, 2]** 上绘制函数图形

2. 在 **x** 轴 **[-0.5, 1.5]** 范围内选取一个随机数，以梯度下降的思想更新 **x** ，使得 **x** 为取到 **y** 在原随机点附近的极小值

3. 将上述过程通过某种方法展示

>**Hint**
>
>学习python中matplotlib的使用

**思考**

无论随机数在何区间，都能达到最小值吗？

梯度下降的局限性

### 任务二：MNIST——灵梦与琪露诺的数字大冒险

![](assets/Cirno.avif)

某天，冰之妖精琪露诺来到博丽神社，兴高采烈地告诉灵梦自己刚刚在外界的某个地方听说了一种“数字挑战”。灵梦一头雾水，但看着琪露诺充满自信的样子，决定教她一点真正的技术，以免她到处闯祸。灵梦决定让琪露诺学习如何使用卷积神经网络来识别手写数字。

- **琪露诺:** 灵梦，我听说外界的那些人类有一种数字挑战，哈哈，他们的智慧不如我，我可是最聪明的！
- **灵梦:** （无奈地叹气）嗯……既然你这么感兴趣，我来教你点真正的东西。外界的这些手写数字其实可以用卷积神经网络来识别，我们可以搭建一个简单的 LeNet 网络。

灵梦拿出了她的笔记本，展示了一个关于数字识别的卷积神经网络架构，并且打开了 MNIST 数据集。这些图片中的数字需要识别，而神社正好有足够的灵力来支撑计算。

- **琪露诺:** 这些数字看上去很简单嘛！我该怎么做？
- **灵梦:** 首先，我们得构建一个卷积神经网络，然后用这个数据集来训练它。完成训练后，你就可以让机器来自动识别这些数字了。

**任务**

1. 构建卷积神经网络LeNet

2. 加载pytorch官方所提供的MNIST数据集

3. 使用数据集中训练数据对模型进行训练

4. 使用训练后模型对数据集中测试数据进行检测并进行精确度计算

>  **可选**
>  
>  尝试去往[Digit Recognizer | Kaggle](https://www.kaggle.com/c/digit-recognizer/overview)使用比赛提供的训练集训练网络，然后提交对验证集的预测结果，同时针对该比赛有很多方法能够在训练时间保持很短的情况下提升精度，可以去网上搜索相关方法与代码

**思考**

卷积神经网络中每一步在整个识别流程中对图片进行了哪些操作，分别有什么意义

### 任务三（附加题）：GPT-2——灵梦的AI交流计划

![](assets/miku.png)

某天，博丽神社的巫女博丽灵梦在闲暇时意外听说外界有一位虚拟歌手，名叫初音未来。她以非凡的歌声和独特的魅力，在外界深受人类喜爱。灵梦对这个虚拟偶像产生了极大的兴趣，心想着，能和这个“虚拟存在”交流应该是件非常有趣的事，于是她决定：**构建一个GPT-2模型**，让她可以与初音未来真正进行互动！

> **Annotation**
> 
> 这道题是出题人在网上发现的非常适合新手入门语言模型项目的代码，通过阅读，能够完整体验训练过程，同时视频内也有很多优化训练速度的技术。难度跨度较大，虽然有很好的指导视频，甚至github仓库代码，但是完整走完还是十分不易
> 
> [【精校】“让我们重现GPT-2（1.24亿参数）!”AI大神Andrej Karpathy最新4小时经典教程 【中英】]( https://www.bilibili.com/video/BV12s421u7sZ/?share_source=copy_web&vd_source=51c4fb30e90a316b418932d56041e4aa)
> 
> 上面的视频完整演示了从0到搭建GPT2完成，搜集训练数据，在验证集上观察分数的过程，倘若拥有足够的计算资源，在训练完成之后甚至分数能够超过目前由Hugging Face官方提供的GPT2模型，但是绝大部分人应该有没有足够计算资源，倒也不必强求结果，学习过程才更为重要，在loss下降以外的地方必定会有很多其他的验证方式。


**学习路线**

1. 第一步是了解自注意力机制详细计算过程，同时思考为什么能够超过原本使用的RNN，LSTM，阅读原论文能够有不错的解释，而李宏毅老师的课程是我觉得讲解最为通俗易懂的：[强烈推荐！台大李宏毅自注意力机制和Transformer详解！](https://www.bilibili.com/video/BV1v3411r78R/?share_source=copy_web&vd_source=51c4fb30e90a316b418932d56041e4aa)详细了解之后，推荐在阅读相关论文之前可以去看看B站up主**跟李沐学AI**的视频，并且阅读全英文论文之前可以提前了解文章内容，方便理解

2. 在pytorch上大模型的代码实际上代码并不复杂，但是在运行过程中可能会出现访问Hugging Face等许多问题，绝大部分遇到的问题可以通过网络搜索解决

3. 或许在缺少资源的情况下并不能完成完整的训练，但是仍旧可以使用现在更加先进的大模型构建技术修改内部模块，比如RMSNorm等，这里举例llama3.1使用的旋转位置编码RoPE。推荐一个旋转编码的讲解视频，通过观看，相信你也能体会到线性代数等数学课的重要性：[解密旋转位置编码：数学基础、代码实现与绝对编码一体化探索](https://www.bilibili.com/video/BV1Xi421R7ev/?share_source=copy_web&vd_source=51c4fb30e90a316b418932d56041e4aa)

**任务**

完成并提交代码

**思考**

1. Hugging Face中transformers库的使用

2. 对于大语言模型，tokenize是什么，当下最为常用的tokenize方法是什么

---

**Ciallo～(∠・ω< )幸苦了**

![](assets/ciallo.jpg)

> **Tips**
> 
>做题是一个学习的过程，希望你能够在做题过程中有所收获，而不是仅从网上cv代码
>
>目的性较强的学习能够让人更快地掌握一件事，但完成的同时也注意不要忽略了过程中极为重要的理论知识唷，并不是代码成功运转了就万事大吉，了解每一行代码的运转逻辑也十分重要
>
>**如果你已经完成了上述全部任务，欢迎咨询出题人有哪些其他的推荐项目** 
>

##### 其余学习资料推荐

[【莫烦Python】PyTorch 神经网络]( https://www.bilibili.com/video/BV1Vx411j7kT/?share_source=copy_web&vd_source=51c4fb30e90a316b418932d56041e4aa)

可以尝试使用远程运算平台如Kaggle Notebook、Google Colab等众多云计算平台